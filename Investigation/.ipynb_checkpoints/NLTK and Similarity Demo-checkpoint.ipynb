{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python and NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language is pretty easy to humans, but really difficult to computers.  \n",
    "\n",
    "### Word sense ambiguity\n",
    "\n",
    "##### \"He served the dish\"\n",
    "**serve**: help with food or drink; hold an office; put ball into play  \n",
    "**dish**: plate; course of a meal; communications device  \n",
    "\n",
    "##### \"... by ...\"\n",
    "\n",
    "- The lost children were found by the **searchers** (agentive)\n",
    "- The lost children were found by the **mountain** (locative)\n",
    "- The lost children were found by the **afternoon** (temporal)\n",
    "\n",
    "### Pronoun resolution\n",
    "- The thieves stole the paintings. **They** were subsequently *sold*.\n",
    "- The thieves stole the paintings. **They** were subsequently *caught*.\n",
    "- The thieves stole the paintings. **They** were subsequently *found*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nltk_download.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty_python = text6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `concordance()`\n",
    "Search text and view context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty_python.concordance('shrubbery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty_python.concordance('Camelot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `similar()`\n",
    "Find other words used in similar context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty_python.similar('castle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dispersion_plot()`\n",
    "graph the location where a word was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inaugural_address = text4\n",
    "inaugural_address.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `bigrams()`\n",
    "generates 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(nltk.bigrams(['to', 'be', 'or', 'not', 'to', 'be']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `collocations()`\n",
    "Find frequent bigrams in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inaugural_address.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty_python.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `FreqDist()` - Frequency Distribution\n",
    "An object consisting of the frequency of each vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inaugural_distribution = nltk.FreqDist(inaugural_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inaugural_distribution.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inaugural_distribution['America']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crude markov chain generator. Uses most common distrubtion in a bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_model(cfdist, word, num=15): \n",
    "    for i in range(num):\n",
    "        print word,\n",
    "        word = cfdist[word].max()\n",
    "     \n",
    "bigram = nltk.bigrams(inaugural_address)\n",
    "cfd = nltk.ConditionalFreqDist(bigram)\n",
    "\n",
    "print cfd['America']\n",
    "generate_model(cfd, 'America')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagger - `pos_tag()`\n",
    "\n",
    "- CC: coordinating conjunction\n",
    "- RB: adverbs\n",
    "- IN: preposition\n",
    "- NN: noun\n",
    "- JJ: adjective\n",
    "- VBD: verb, past tense\n",
    "- DT: determiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = nltk.word_tokenize(\"The quick brown fox jumped over the lazy dog\")\n",
    "nltk.pos_tag(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similiarity\n",
    "$$J(A,B) = \\frac{| A \\cap B |}{| A \\cup B |}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_char_ngram(string, n):\n",
    "    length = len(string)\n",
    "    \n",
    "    ngram_list = list()\n",
    "    \n",
    "    for index in range(length-1):\n",
    "        ngram_list.append(string[index:index+2])\n",
    "        \n",
    "    return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similiarty(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    return len(set1.intersection(set2)) / float(len(set1.union(set2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string1 = 'kitten'\n",
    "string2 = 'sitting'\n",
    "\n",
    "ngram1 = generate_char_ngram(string1, 2)\n",
    "ngram2 = generate_char_ngram(string2, 2)\n",
    "\n",
    "jaccard_similiarty(ngram1, ngram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string3 = 'google'\n",
    "string4 = 'googleinc'\n",
    "\n",
    "ngram3 = generate_char_ngram(string3, 2)\n",
    "ngram4 = generate_char_ngram(string4, 2)\n",
    "\n",
    "jaccard_similiarty(ngram3, ngram4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "$$ similarity = cos(\\theta) = \\frac {A \\cdot B}{||A||\\cdot||B||} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_strings(string1, string2):\n",
    "    ngram1 = generate_char_ngram(string1, 2)\n",
    "    ngram2 = generate_char_ngram(string2, 2)\n",
    "    \n",
    "    ## Set are unordered, but that's ok for our purposes\n",
    "    n = set(ngram1).union(set(ngram2))\n",
    "    \n",
    "    element1 = [0] * len(n)\n",
    "    element2 = [0] * len(n)\n",
    "    \n",
    "    ## Loop through the union set of ngrams and check if they show up in string 1 and 2\n",
    "    for index, ngram in enumerate(n):\n",
    "        if ngram in ngram1:\n",
    "            element1[index] = 1\n",
    "        else:\n",
    "            element1[index] = 0\n",
    "            \n",
    "        if ngram in ngram2:\n",
    "            element2[index] = 1\n",
    "        else:\n",
    "            element2[index] = 0\n",
    "            \n",
    "    return (element1, element2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    a = np.asarray(vector1)\n",
    "    b = np.asarray(vector2)\n",
    "    result = np.dot(a, b) / float(np.linalg.norm(a)) / float(np.linalg.norm(b))\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1, v2 = vectorize_strings('google', 'googleinc')\n",
    "cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein / Edit Distance\n",
    "\n",
    "Borrowed from Wikipedia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Christopher P. Matthews\n",
    "# christophermatthews1985@gmail.com\n",
    "# Sacramento, CA, USA\n",
    "\n",
    "def levenshtein_distance(s, t):\n",
    "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
    "        if s == t: return 0\n",
    "        elif len(s) == 0: return len(t)\n",
    "        elif len(t) == 0: return len(s)\n",
    "        v0 = [None] * (len(t) + 1)\n",
    "        v1 = [None] * (len(t) + 1)\n",
    "        for i in range(len(v0)):\n",
    "            v0[i] = i\n",
    "        for i in range(len(s)):\n",
    "            v1[0] = i + 1\n",
    "            for j in range(len(t)):\n",
    "                cost = 0 if s[i] == t[j] else 1\n",
    "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
    "            for j in range(len(v0)):\n",
    "                v0[j] = v1[j]\n",
    "                \n",
    "        return v1[len(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levenshtein_distance('kitten', 'sitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
